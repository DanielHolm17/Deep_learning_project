{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8efa13d2",
   "metadata": {},
   "source": [
    "# Project: Fruit detection\n",
    "\n",
    "The model should be able to detect multiple fruits in a single picture. \n",
    "The concept is that the model should be used in super markets for self checkout so the shopping experience will get easier. \n",
    "Here the model will detect the fruits automatically instead of the customer manually writing how many of a certian fruit they have bought. \n",
    "Furthermore the model could be used by cashiers, so they also wouldn't have to write in a specific number that represents a fruit. \n",
    "In general the model could be expanded to detect any product without a barcode.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e9eafc",
   "metadata": {},
   "source": [
    "Including libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0348b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import numpy\n",
    "\n",
    "import torch\n",
    "from torch.nn import Linear, CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda60788",
   "metadata": {},
   "source": [
    "# Preparing data\n",
    "Creating merged images with 2-6 random fruits in them, and creating a csv file to keep track of number of fruits (labels) in each of the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a982cb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randint\n",
    "import random\n",
    "import array as arr\n",
    "from PIL import Image\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "f = open('training_classes.csv', 'w', newline='')\n",
    "writer = csv.writer(f)\n",
    "\n",
    "for i in range (2500):\n",
    "    numberOfFruits = randint(2, 6)\n",
    "    img = []\n",
    "    classes = [0, 0, 0, 0, 0]       # [Apple, Clem, Kiwi, Orange, Pear]\n",
    "\n",
    "    for j in range(numberOfFruits):\n",
    "        path = 'Training'\n",
    "        subFolder = os.listdir(path)\n",
    "        pathSubFolder = random.choice(subFolder)\n",
    "        path = path + \"/\" + pathSubFolder\n",
    "\n",
    "        if pathSubFolder == \"Apple Pink Lady\":\n",
    "            classes[0] = classes[0] + 1\n",
    "        elif pathSubFolder == \"Clementine\":\n",
    "            classes[1] = classes[1] + 1\n",
    "        elif pathSubFolder == \"Kiwi\":\n",
    "            classes[2] = classes[2] + 1\n",
    "        elif pathSubFolder == \"Orange\":\n",
    "            classes[3] = classes[3] + 1\n",
    "        elif pathSubFolder == \"Pear\":\n",
    "            classes[4] = classes[4] + 1\n",
    "\n",
    "        images = os.listdir(path)\n",
    "        rndImage = random.choice(images)\n",
    "\n",
    "        img.append(Image.open(path+\"/\"+rndImage))\n",
    "\n",
    "    img_size = img[0].size\n",
    "    new_image = Image.new('RGB',(6*img_size[0], 6*img_size[1]), (250,250,250))\n",
    "    \n",
    "    rndVec = np.zeros((numberOfFruits, 2), dtype=int)\n",
    "\n",
    "    for j in range(numberOfFruits):\n",
    "        rndVec[j] = np.random.randint(6, size=2)\n",
    "\n",
    "        for u in range(j):\n",
    "            if j != u: \n",
    "                while rndVec[j][0] == rndVec[u][0] and rndVec[j][1] == rndVec[u][1]:\n",
    "                    rndVec[j] = np.random.randint(6, size=2)\n",
    "\n",
    "        if j > 2:\n",
    "            new_image.paste(img[j], (img_size[0]*rndVec[j][0],img_size[1]*rndVec[j][1]))\n",
    "        else:\n",
    "            new_image.paste(img[j], (img_size[0]*rndVec[j][0],img_size[1]*rndVec[j][1]))\n",
    "\n",
    "    string = 'training_merged_images/mergedImage_{}.jpg'.format(i)\n",
    "    new_image.save(string, \"JPEG\")\n",
    "\n",
    "    line = ['mergedImage_{}'.format(i), classes]\n",
    "    writer.writerow(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e3faaf",
   "metadata": {},
   "source": [
    "Doing the same for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bffa68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('validation_classes.csv', 'w', newline='')\n",
    "writer = csv.writer(f)\n",
    "\n",
    "for i in range (500):\n",
    "    numberOfFruits = randint(2, 6)\n",
    "    img = []\n",
    "    classes = [0, 0, 0, 0, 0]       # [Apple, Clem, Kiwi, Orange, Pear]\n",
    "\n",
    "    for j in range(numberOfFruits):\n",
    "        path = 'Validation'\n",
    "        subFolder = os.listdir(path)\n",
    "        pathSubFolder = random.choice(subFolder)\n",
    "        path = path + \"/\" + pathSubFolder\n",
    "\n",
    "        if pathSubFolder == \"Apple Pink Lady\":\n",
    "            classes[0] = classes[0] + 1\n",
    "        elif pathSubFolder == \"Clementine\":\n",
    "            classes[1] = classes[1] + 1\n",
    "        elif pathSubFolder == \"Kiwi\":\n",
    "            classes[2] = classes[2] + 1\n",
    "        elif pathSubFolder == \"Orange\":\n",
    "            classes[3] = classes[3] + 1\n",
    "        elif pathSubFolder == \"Pear\":\n",
    "            classes[4] = classes[4] + 1\n",
    "\n",
    "        images = os.listdir(path)\n",
    "        rndImage = random.choice(images)\n",
    "\n",
    "        img.append(Image.open(path+\"/\"+rndImage))\n",
    "\n",
    "    img_size = img[0].size\n",
    "    new_image = Image.new('RGB',(6*img_size[0], 6*img_size[1]), (250,250,250))\n",
    "\n",
    "    rndVec = np.zeros((numberOfFruits, 2), dtype=int)\n",
    "\n",
    "    for j in range(numberOfFruits):\n",
    "        rndVec[j] = np.random.randint(6, size=2)\n",
    "\n",
    "        for u in range(j):\n",
    "            if j != u: \n",
    "                while rndVec[j][0] == rndVec[u][0] and rndVec[j][1] == rndVec[u][1]:\n",
    "                    rndVec[j] = np.random.randint(6, size=2)\n",
    "\n",
    "        if j > 2:\n",
    "            new_image.paste(img[j], (img_size[0]*rndVec[j][0],img_size[1]*rndVec[j][1]))\n",
    "        else:\n",
    "            new_image.paste(img[j], (img_size[0]*rndVec[j][0],img_size[1]*rndVec[j][1]))\n",
    "\n",
    "    string = 'validation_merged_images/mergedImage_{}.jpg'.format(i)\n",
    "    new_image.save(string, \"JPEG\")\n",
    "\n",
    "    line = ['mergedImage_{}'.format(i), classes]\n",
    "    writer.writerow(line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ff251ad",
   "metadata": {},
   "source": [
    "Creating the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdf2733",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('test_classes.csv', 'w', newline='')\n",
    "writer = csv.writer(f)\n",
    "line = ['0_1_1_0_2'.format(), [0, 1, 1, 0, 2]]\n",
    "writer.writerow(line)\n",
    "line = ['0_1_1_0_2_a'.format(), [0, 1, 1, 0, 2]]\n",
    "writer.writerow(line)\n",
    "line = ['0_1_1_1_0'.format(), [0, 1, 1, 1, 0]]\n",
    "writer.writerow(line)\n",
    "line = ['0_1_2_0_0'.format(), [0, 1, 2, 0, 0]]\n",
    "writer.writerow(line)\n",
    "line = ['0_1_2_1_0'.format(), [0, 1, 2, 1, 0]]\n",
    "writer.writerow(line)\n",
    "line = ['0_2_0_0_0'.format(), [0, 2, 0, 0, 0]]\n",
    "writer.writerow(line)\n",
    "line = ['0_2_0_1_0'.format(), [0, 2, 0, 1, 0]]\n",
    "writer.writerow(line)\n",
    "line = ['0_2_2_0_1'.format(), [0, 2, 2, 0, 1]]\n",
    "writer.writerow(line)\n",
    "line = ['0_2_2_1_0'.format(), [0, 2, 2, 1, 0]]\n",
    "writer.writerow(line)\n",
    "line = ['1_0_0_0_0'.format(), [1, 0, 0, 0, 0]]\n",
    "writer.writerow(line)\n",
    "line = ['1_0_0_0_2'.format(), [1, 0, 0, 0, 2]]\n",
    "writer.writerow(line)\n",
    "line = ['1_0_0_0_2_a'.format(), [1, 0, 0, 0, 2]]\n",
    "writer.writerow(line)\n",
    "line = ['1_0_1_0_1'.format(), [1, 0, 1, 0, 1]]\n",
    "writer.writerow(line)\n",
    "line = ['1_0_1_0_2'.format(), [1, 0, 1, 0, 2]]\n",
    "writer.writerow(line)\n",
    "line = ['1_0_1_2_1'.format(), [1, 0, 1, 2, 1]]\n",
    "writer.writerow(line)\n",
    "line = ['1_1_0_1_1'.format(), [1, 1, 0, 1, 1]]\n",
    "writer.writerow(line)\n",
    "line = ['1_1_1_0_1'.format(), [1, 1, 1, 0, 1]]\n",
    "writer.writerow(line)\n",
    "line = ['1_1_1_0_1_a'.format(), [1, 1, 1, 0, 1]]\n",
    "writer.writerow(line)\n",
    "line = ['1_1_1_0_2'.format(), [1, 1, 1, 0, 2]]\n",
    "writer.writerow(line)\n",
    "line = ['1_1_1_1_0'.format(), [1, 1, 1, 1, 0]]\n",
    "writer.writerow(line)\n",
    "line = ['1_1_1_1_2'.format(), [1, 1, 1, 1, 2]]\n",
    "writer.writerow(line)\n",
    "line = ['1_2_1_0_1'.format(), [1, 2, 1, 0, 1]]\n",
    "writer.writerow(line)\n",
    "line = ['2_1_1_1_0'.format(), [2, 1, 1, 1, 0]]\n",
    "writer.writerow(line)\n",
    "line = ['3_0_1_1_1'.format(), [3, 0, 1, 1, 1]]\n",
    "writer.writerow(line)\n",
    "line = ['3_1_0_0_0'.format(), [3, 1, 0, 0, 0]]\n",
    "writer.writerow(line)\n",
    "line = ['4_1_0_0_0'.format(), [4, 1, 0, 0, 0]]\n",
    "writer.writerow(line)\n",
    "line = ['0_0_0_0_2'.format(), [0, 0, 0, 0, 2]]\n",
    "writer.writerow(line)\n",
    "line = ['0_0_1_0_0'.format(), [0, 0, 1, 0, 0]]\n",
    "writer.writerow(line)\n",
    "line = ['0_0_1_1_1'.format(), [0, 0, 1, 1, 1]]\n",
    "writer.writerow(line)\n",
    "line = ['0_0_2_0_0'.format(), [0, 0, 2, 0, 0]]\n",
    "writer.writerow(line)\n",
    "line = ['0_1_0_0_0'.format(), [0, 1, 0, 0, 0]]\n",
    "writer.writerow(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36d21da",
   "metadata": {},
   "source": [
    "# Creating a dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf32e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "class GenericFruitDataset(Dataset):\n",
    "  def __init__(self, folderPath, fruit, csvName):\n",
    "    #path to the folder of all the images.\n",
    "    nameOfFile = 0\n",
    "    labelOfFile = 0\n",
    "    res = []\n",
    "    nameRes = []\n",
    "    mydict = {}\n",
    "    with open(csvName) as csv_file:\n",
    "      csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "      \n",
    "      for row in csv_reader:\n",
    "        mydict[row[0]+'.jpg']= row[1]\n",
    "        \n",
    "      self.imgs_path = folderPath\n",
    "\n",
    "      self.data = []\n",
    "      for file in os.listdir(folderPath):\n",
    "            #get name of file\n",
    "            img_path = os.path.join(folderPath, file)\n",
    "            if fruit == 'apple':\n",
    "              if file in mydict.keys():\n",
    "                labelOfFile = mydict[file]\n",
    "                self.class_name = labelOfFile[1]\n",
    "                self.class_map = {labelOfFile[1]: 0}\n",
    "                self.data.append([img_path, labelOfFile[1]])\n",
    "            if fruit == 'clementine':\n",
    "              if file in mydict.keys():\n",
    "                labelOfFile = mydict[file]\n",
    "                self.class_name = labelOfFile[4]\n",
    "                self.class_map = {labelOfFile[4]: 0}\n",
    "                self.data.append([img_path, labelOfFile[4]])\n",
    "            if fruit == 'kiwi':\n",
    "              if file in mydict.keys():\n",
    "                labelOfFile = mydict[file]\n",
    "                self.class_name = labelOfFile[7]\n",
    "                self.class_map = {labelOfFile[7]: 0}\n",
    "                self.data.append([img_path, labelOfFile[7]])\n",
    "            if fruit == 'orange':\n",
    "              if file in mydict.keys():\n",
    "                labelOfFile = mydict[file]\n",
    "                self.class_name = labelOfFile[10]\n",
    "                self.class_map = {labelOfFile[10]: 0}\n",
    "                self.data.append([img_path, labelOfFile[10]])\n",
    "            if fruit == 'pear':\n",
    "              if file in mydict.keys():\n",
    "                labelOfFile = mydict[file]\n",
    "                self.class_name = labelOfFile[13]\n",
    "                self.class_map = {labelOfFile[13]: 0}\n",
    "                self.data.append([img_path, labelOfFile[13]])\n",
    "  \n",
    "      self.img_dim = (224, 224)\n",
    "\n",
    "  #Define size function\n",
    "  def __len__(self):\n",
    "      return len(self.data)\n",
    "  #Defining the retrieval of an object\n",
    "  def __getitem__(self, idx):\n",
    "      imagepath, class_name = self.data[idx]\n",
    "      img = cv2.imread(imagepath)\n",
    "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "      img = cv2.resize(img, self.img_dim)\n",
    "      img_tensor = torch.from_numpy(img)\n",
    "      img_tensor = img_tensor.permute(2, 0, 1)\n",
    "      #Class id is inserted into a tensor\n",
    "      class_id = int(class_name)\n",
    "      class_id = torch.tensor([class_id])\n",
    "      return img_tensor, class_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45229ffa",
   "metadata": {},
   "source": [
    "Creating apple train and validation set and testing output of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d18c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "apple_trainSet = GenericFruitDataset(\"training_merged_images\", 'apple', 'training_classes.csv')\n",
    "apple_validationSet = GenericFruitDataset(\"validation_merged_images\", 'apple', 'validation_classes.csv')\n",
    "apple_testSet = GenericFruitDataset(\"Test/test_set\", 'apple', 'test_classes.csv')\n",
    "\n",
    "clementine_trainSet = GenericFruitDataset(\"training_merged_images\", 'clementine', 'training_classes.csv')\n",
    "clementine_validationSet = GenericFruitDataset(\"validation_merged_images\", 'clementine', 'validation_classes.csv')\n",
    "clementine_testSet = GenericFruitDataset(\"Test/test_set\", 'clementine', 'test_classes.csv')\n",
    "\n",
    "kiwi_trainSet = GenericFruitDataset(\"training_merged_images\", 'kiwi', 'training_classes.csv')\n",
    "kiwi_validationSet = GenericFruitDataset(\"validation_merged_images\", 'kiwi', 'validation_classes.csv')\n",
    "kiwi_testSet = GenericFruitDataset(\"Test/test_set\", 'kiwi', 'test_classes.csv')\n",
    "\n",
    "orange_trainSet = GenericFruitDataset(\"training_merged_images\", 'orange', 'training_classes.csv')\n",
    "orange_validationSet = GenericFruitDataset(\"validation_merged_images\", 'orange', 'validation_classes.csv')\n",
    "orange_testSet = GenericFruitDataset(\"Test/test_set\", 'orange', 'test_classes.csv')\n",
    "\n",
    "pear_trainSet = GenericFruitDataset(\"training_merged_images\", 'pear', 'training_classes.csv')\n",
    "pear_validationSet = GenericFruitDataset(\"validation_merged_images\", 'pear', 'validation_classes.csv')\n",
    "pear_testSet = GenericFruitDataset(\"Test/test_set\", 'pear', 'test_classes.csv')\n",
    "\n",
    "images, labels = apple_trainSet.__getitem__(5)\n",
    "plt.figure()\n",
    "plt.imshow(images.permute(1, 2, 0))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738b1ad1",
   "metadata": {},
   "source": [
    "Creating dataloaders with batchsize, and printing shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a263c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "BATCH_SIZE = 8\n",
    "apple_train_dataloader = DataLoader(dataset=apple_trainSet, batch_size=BATCH_SIZE, shuffle=True)\n",
    "apple_validation_dataloader = DataLoader(dataset=apple_validationSet, batch_size=BATCH_SIZE, shuffle=True)\n",
    "apple_test_dataloader = DataLoader(dataset=apple_testSet, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "clementine_train_dataloader = DataLoader(dataset=clementine_trainSet, batch_size=BATCH_SIZE, shuffle=True)\n",
    "clementine_validation_dataloader = DataLoader(dataset=clementine_validationSet, batch_size=BATCH_SIZE, shuffle=True)\n",
    "clementine_test_dataloader = DataLoader(dataset=clementine_testSet, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "kiwi_train_dataloader = DataLoader(dataset=kiwi_trainSet, batch_size=BATCH_SIZE, shuffle=True)\n",
    "kiwi_validation_dataloader = DataLoader(dataset=kiwi_validationSet, batch_size=BATCH_SIZE, shuffle=True)\n",
    "kiwi_test_dataloader = DataLoader(dataset=kiwi_testSet, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "orange_train_dataloader = DataLoader(dataset=orange_trainSet, batch_size=BATCH_SIZE, shuffle=True)\n",
    "orange_validation_dataloader = DataLoader(dataset=orange_validationSet, batch_size=BATCH_SIZE, shuffle=True)\n",
    "orange_test_dataloader = DataLoader(dataset=orange_testSet, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "pear_train_dataloader = DataLoader(dataset=pear_trainSet, batch_size=BATCH_SIZE, shuffle=True)\n",
    "pear_validation_dataloader = DataLoader(dataset=pear_validationSet, batch_size=BATCH_SIZE, shuffle=True)\n",
    "pear_test_dataloader = DataLoader(dataset=pear_testSet, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "train_features, train_labels = next(iter(apple_train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img.permute(1, 2, 0), cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7baabc",
   "metadata": {},
   "source": [
    "# Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2c99679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "model_apple = resnet18(pretrained=True)\n",
    "model_clementine = resnet18(pretrained=True)\n",
    "model_kiwi = resnet18(pretrained=True)\n",
    "model_orange = resnet18(pretrained=True)\n",
    "model_pear = resnet18(pretrained=True)\n",
    "\n",
    "#models = [model_apple]\n",
    "models = [model_apple, model_clementine, model_kiwi, model_orange, model_pear]\n",
    "\n",
    "for model in models:\n",
    "    # Freeze layer 1 2 3 \n",
    "    for params in model.layer1.parameters():\n",
    "        params.requires_grad = False\n",
    "    for params in model.layer2.parameters():\n",
    "        params.requires_grad = False\n",
    "\n",
    "    # Replace Output of Fully Connected Layer with Number of Labels for our Classification Problem\n",
    "    model.fc = Linear(in_features=512, out_features=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd875040",
   "metadata": {},
   "source": [
    "Printing the trainable parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d11ceb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------+\n",
      "|           Modules            | Parameters |\n",
      "+------------------------------+------------+\n",
      "|         conv1.weight         |    9408    |\n",
      "|          bn1.weight          |     64     |\n",
      "|           bn1.bias           |     64     |\n",
      "|    layer3.0.conv1.weight     |   294912   |\n",
      "|     layer3.0.bn1.weight      |    256     |\n",
      "|      layer3.0.bn1.bias       |    256     |\n",
      "|    layer3.0.conv2.weight     |   589824   |\n",
      "|     layer3.0.bn2.weight      |    256     |\n",
      "|      layer3.0.bn2.bias       |    256     |\n",
      "| layer3.0.downsample.0.weight |   32768    |\n",
      "| layer3.0.downsample.1.weight |    256     |\n",
      "|  layer3.0.downsample.1.bias  |    256     |\n",
      "|    layer3.1.conv1.weight     |   589824   |\n",
      "|     layer3.1.bn1.weight      |    256     |\n",
      "|      layer3.1.bn1.bias       |    256     |\n",
      "|    layer3.1.conv2.weight     |   589824   |\n",
      "|     layer3.1.bn2.weight      |    256     |\n",
      "|      layer3.1.bn2.bias       |    256     |\n",
      "|    layer4.0.conv1.weight     |  1179648   |\n",
      "|     layer4.0.bn1.weight      |    512     |\n",
      "|      layer4.0.bn1.bias       |    512     |\n",
      "|    layer4.0.conv2.weight     |  2359296   |\n",
      "|     layer4.0.bn2.weight      |    512     |\n",
      "|      layer4.0.bn2.bias       |    512     |\n",
      "| layer4.0.downsample.0.weight |   131072   |\n",
      "| layer4.0.downsample.1.weight |    512     |\n",
      "|  layer4.0.downsample.1.bias  |    512     |\n",
      "|    layer4.1.conv1.weight     |  2359296   |\n",
      "|     layer4.1.bn1.weight      |    512     |\n",
      "|      layer4.1.bn1.bias       |    512     |\n",
      "|    layer4.1.conv2.weight     |  2359296   |\n",
      "|     layer4.1.bn2.weight      |    512     |\n",
      "|      layer4.1.bn2.bias       |    512     |\n",
      "|          fc.weight           |   512000   |\n",
      "|           fc.bias            |    1000    |\n",
      "+------------------------------+------------+\n",
      "Total Trainable Params: 11015976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11015976"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    \n",
    "count_parameters(model_apple)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d8f1aea",
   "metadata": {},
   "source": [
    "finding length of train, validation and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa5619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "\n",
    "lenOfTrain = len(fnmatch.filter(os.listdir('training_merged_images'), '*.jpg'))\n",
    "lenOfVal = len(fnmatch.filter(os.listdir('validation_merged_images'), '*.jpg'))\n",
    "lenOfTest = len(fnmatch.filter(os.listdir('Test/test_set'), '*.jpg'))\n",
    "\n",
    "print(lenOfTrain)\n",
    "print(lenOfVal)\n",
    "print(lenOfTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92c5fed",
   "metadata": {},
   "source": [
    "Training and validating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e660ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "\n",
    "for model in models:\n",
    "  optimiser = Adam(model.parameters(), lr=0.0003, weight_decay=0.0001)\n",
    "  loss_fn = nn.MSELoss()\n",
    "\n",
    "  train = 0\n",
    "\n",
    "  if model == model_apple:\n",
    "    print(\"Apple model\")\n",
    "    train = apple_train_dataloader\n",
    "  elif model == model_clementine:\n",
    "    print(\"Clementine model\")\n",
    "    train = clementine_train_dataloader\n",
    "  elif model == model_kiwi:\n",
    "    print(\"Kiwi model\")\n",
    "    train = kiwi_train_dataloader\n",
    "  elif model == model_orange:\n",
    "    print(\"Orange model\")\n",
    "    train = orange_train_dataloader\n",
    "  elif model == model_pear:\n",
    "    print(\"Pear model\")\n",
    "    train =pear_train_dataloader\n",
    "\n",
    "  for epoch in range(5):\n",
    "      start = time()\n",
    "      \n",
    "      tr_acc = 0\n",
    "      true_p = 0\n",
    "      false_p = 0\n",
    "      false_n = 0\n",
    "\n",
    "      predLabels = np.empty((0,))\n",
    "      trueLabels = np.empty((0,))\n",
    "\n",
    "      # Train\n",
    "      model.train()\n",
    "      \n",
    "      with tqdm(train, unit=\"batch\") as tepoch:\n",
    "          for xtrain, ytrain in tepoch:\n",
    "              xtrain = xtrain.float()\n",
    "              ytrain = ytrain.float()\n",
    "              optimiser.zero_grad()\n",
    "              \n",
    "              train_prob = model(xtrain)\n",
    "              train_prob = train_prob.cpu()\n",
    "              \n",
    "              loss = loss_fn(train_prob, ytrain)\n",
    "              loss.backward()\n",
    "              optimiser.step()\n",
    "              \n",
    "              # training ends              \n",
    "              train_pred = abs(torch.round(train_prob))\n",
    "              tr_acc += int(torch.sum(torch.eq(train_pred,ytrain)))              \n",
    "\n",
    "              predLabels = np.append(predLabels, train_pred.detach().numpy())\n",
    "              trueLabels = np.append(trueLabels, ytrain)\n",
    "              train_acc.append(np.mean(predLabels == trueLabels))\n",
    "\n",
    "          ep_tr_acc = tr_acc / (lenOfTrain)     #len train set\n",
    "          predLabels = np.empty((0,))\n",
    "          trueLabels = np.empty((0,))\n",
    "\n",
    "      end = time()\n",
    "      duration = (end - start) / 60\n",
    "      \n",
    "      print(f\"Epoch: {epoch}, Time: {duration}, Loss: {loss}\\nTrain_acc: {ep_tr_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068634e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_acc[0:625], label = \"Apple\")\n",
    "plt.plot(train_acc[626:1251], label = \"Clementine\")\n",
    "plt.plot(train_acc[1252:1877], label = \"Kiwi\")\n",
    "plt.plot(train_acc[1878:2503], label = \"Orange\")\n",
    "plt.plot(train_acc[2504:3129], label = \"Pear\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.ylim(0,1.05)\n",
    "plt.xlim(0,626)\n",
    "plt.xlabel('No of batches')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41b5403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "#torch.save(model_apple, 'Model/model_apple.pth')\n",
    "#torch.save(model_clementine, 'Model/model_clementine.pth')\n",
    "#torch.save(model_kiwi, 'Model/model_kiwi.pth')\n",
    "#torch.save(model_orange, 'Model/model_orange.pth')\n",
    "#torch.save(model_pear, 'Model/model_pear.pth')\n",
    "\n",
    "# load model back in:       model1234 = torch.load('Model/model_apple.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "badc49dd",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f466c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_acc = []\n",
    "\n",
    "for model in models:\n",
    "\n",
    "  validation = 0\n",
    "# \n",
    "  if model == model_apple:\n",
    "    print(\"Apple model\")\n",
    "    validation = apple_validation_dataloader\n",
    "  elif model == model_clementine:\n",
    "    print(\"Clementine model\")\n",
    "    validation = clementine_validation_dataloader\n",
    "  elif model == model_kiwi:\n",
    "    print(\"Kiwi model\")\n",
    "    validation = kiwi_validation_dataloader\n",
    "  elif model == model_orange:\n",
    "    print(\"Orange model\")\n",
    "    validation = orange_validation_dataloader\n",
    "  elif model == model_pear:\n",
    "    print(\"Pear model\")\n",
    "    validation = pear_validation_dataloader\n",
    "\n",
    "  for epoch in range(1):\n",
    "      start = time()\n",
    "    \n",
    "      va_acc = 0\n",
    "\n",
    "      predLabels = np.empty((0,))\n",
    "      trueLabels = np.empty((0,))\n",
    "\n",
    "      # Evaluate\n",
    "      model.eval()\n",
    "      with torch.no_grad() and tqdm(validation, unit=\"batch\") as validation_tepoch:\n",
    "          for xvalidation, yvalidation in validation_tepoch:\n",
    "              xvalidation = xvalidation.float()\n",
    "              yvalidation = yvalidation.float()\n",
    "              validation_prob = model(xvalidation)\n",
    "              validation_prob = validation_prob.cpu()\n",
    "              \n",
    "              validation_pred = abs(torch.round(validation_prob))\n",
    "              va_acc += int(torch.sum(torch.eq(validation_pred,yvalidation)))\n",
    "              \n",
    "              predLabels = np.append(predLabels, validation_pred.detach().numpy())\n",
    "              trueLabels = np.append(trueLabels, yvalidation)\n",
    "              validation_acc.append(np.mean(predLabels == trueLabels))\n",
    "              \n",
    "          ep_validation_acc = va_acc / (lenOfVal)     #len of validation set\n",
    "      \n",
    "      end = time()\n",
    "      duration = (end - start) / 60\n",
    "      \n",
    "      print(f\"Epoch: {epoch}, Time: {duration}, Loss: {loss}\\nValidation_acc: {ep_validation_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca2592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(validation_acc[0:63], label = \"Apple\")\n",
    "plt.plot(validation_acc[63:126], label = \"Clementine\")\n",
    "plt.plot(validation_acc[126:189], label = \"Kiwi\")\n",
    "plt.plot(validation_acc[189:252], label = \"Orange\")\n",
    "plt.plot(validation_acc[252:315], label = \"Pear\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.ylim(0,1.05)\n",
    "plt.xlim(0,63)\n",
    "plt.xlabel('No of batches')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7076a67",
   "metadata": {},
   "source": [
    "# Testing model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9af8d9ac",
   "metadata": {},
   "source": [
    "Test af random billeder fra testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa265c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_labels = [0, 0, 0, 0 ,0]\n",
    "true_labels = [0, 0, 0, 0, 0]\n",
    "counter = 0\n",
    "\n",
    "imgNo = 10\n",
    "\n",
    "images, label1 = apple_validationSet.__getitem__(imgNo)\n",
    "images, label2 = clementine_validationSet.__getitem__(imgNo)\n",
    "images, label3 = kiwi_validationSet.__getitem__(imgNo)\n",
    "images, label4 = orange_validationSet.__getitem__(imgNo)\n",
    "images, label5 = pear_validationSet.__getitem__(imgNo)\n",
    "\n",
    "#true_labels = [label1.item(), label2.item(), label3.item(), label4.item(), label5.item(),]\n",
    "\n",
    "images = cv2.imread('Test/test_set_troll/1_2_0_0_1_t.jpg')\n",
    "images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB)\n",
    "images = cv2.resize(images, (224, 224))\n",
    "\n",
    "images = torch.from_numpy(images)\n",
    "images = images.permute(2, 0, 1)\n",
    "\n",
    "true_labels = [1, 2, 1, 0, 0]\n",
    "\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "plt.imshow(images.permute(1,2,0))\n",
    "plt.show()\n",
    "\n",
    "for model in models:\n",
    "    img_tensor = images.unsqueeze(0)\n",
    "    pred_prob = model(img_tensor.float())\n",
    "    pred_labels[counter] = abs(torch.round(pred_prob)).item()\n",
    "    counter = counter + 1\n",
    "\n",
    "print(\"Predicted label:\", pred_labels)\n",
    "print(\"True label:\", true_labels, \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5755d40d",
   "metadata": {},
   "source": [
    "Test entire test set and calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aae22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = []\n",
    "\n",
    "for model in models:\n",
    "\n",
    "  test = 0\n",
    "\n",
    "  if model == model_apple:\n",
    "    test = apple_test_dataloader\n",
    "  elif model == model_clementine:\n",
    "    test = clementine_test_dataloader\n",
    "  elif model == model_kiwi:\n",
    "    test = kiwi_test_dataloader\n",
    "  elif model == model_orange:\n",
    "    test = orange_test_dataloader\n",
    "  elif model == model_pear:\n",
    "    test = pear_test_dataloader\n",
    "\n",
    "  for epoch in range(1):\n",
    "      start = time()\n",
    "    \n",
    "      te_acc = 0\n",
    "\n",
    "      predLabels = np.empty((0,))\n",
    "      trueLabels = np.empty((0,))\n",
    "\n",
    "      # Evaluate\n",
    "      model.eval()\n",
    "      with torch.no_grad() and tqdm(test, unit=\"batch\") as test_tepoch:\n",
    "          for xtest, ytest in test_tepoch:\n",
    "              xtest = xtest.float()\n",
    "              ytest = ytest.float()\n",
    "              test_prob = model(xtest)\n",
    "              test_prob = test_prob.cpu()\n",
    "              \n",
    "              test_pred = abs(torch.round(test_prob))\n",
    "              te_acc += int(torch.sum(torch.eq(test_pred,ytest)))\n",
    "              \n",
    "              predLabels = np.append(predLabels, test_pred.detach().numpy())\n",
    "              trueLabels = np.append(trueLabels, ytest)\n",
    "              test_acc.append(np.mean(predLabels == trueLabels))\n",
    "              \n",
    "          ep_test_acc = te_acc / (lenOfTest)     #len of test set\n",
    "      \n",
    "      end = time()\n",
    "      duration = (end - start) / 60\n",
    "      \n",
    "      print(f\"Epoch: {epoch}, Time: {duration}, Loss: {loss}\\nTest_acc: {ep_test_acc}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd050ee4",
   "metadata": {},
   "source": [
    "Test on data with other objects and a dark background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed2e133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Performance\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "img = cv2.imread('Test/test_set_troll/1_0_0_1_2_t.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (224, 224))\n",
    "img_tensor = torch.from_numpy(img)\n",
    "img_tensor1 = img_tensor.permute(2, 0, 1)\n",
    "\n",
    "img = cv2.imread('Test/test_set_troll/0_2_1_0_1_t.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (224, 224))\n",
    "img_tensor = torch.from_numpy(img)\n",
    "img_tensor2 = img_tensor.permute(2, 0, 1)\n",
    "\n",
    "img = cv2.imread('Test/test_set_troll/1_2_0_0_1_t.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (224, 224))\n",
    "img_tensor = torch.from_numpy(img)\n",
    "img_tensor3 = img_tensor.permute(2, 0, 1)\n",
    "\n",
    "img = cv2.imread('Test/test_set_troll/1_2_1_0_0_t.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (224, 224))\n",
    "img_tensor = torch.from_numpy(img)\n",
    "img_tensor4 = img_tensor.permute(2, 0, 1)\n",
    "\n",
    "\n",
    "sample_list = [(img_tensor1, torch.tensor([1])),\n",
    "               (img_tensor2, torch.tensor([0])),\n",
    "               (img_tensor3, torch.tensor([1])),\n",
    "               (img_tensor4, torch.tensor([1]))]\n",
    "\n",
    "for image,label in sample_list:\n",
    "    plt.figure()\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    img_tensor = image.unsqueeze(0)\n",
    "    pred_prob = model_orange(img_tensor.float())\n",
    "    pred = abs(torch.round(pred_prob))\n",
    "    print(\"Predicted label:\", pred.item(),  \"- Predicted probability:\", pred_prob.item())\n",
    "    print(\"True label:\", label.item(), \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d9defa72c2715dab9f7f172572cd30a1ab1a2083462d32ef96aadb7c6e0c73b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
